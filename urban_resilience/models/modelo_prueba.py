#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""Copy of ModeloMonica.ipynb

Automatically generated by Colaboratory.

Original file is located at
      https://colab.research.google.com/drive/1p_FfPqGtxpgRg1h2DlPysZLUpAtlGsa1

# Imports
"""

#!pip3 install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio==0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html

import torch
from torch.autograd import Variable
import torch.nn as nn
from sklearn.model_selection import train_test_split
from sklearn import datasets
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#  from google.colab import drive
#  drive.mount('/content/drive')

"""# Se utilizaron datos del [Portal de Datos Abiertos de la CDMX](https://datos.cdmx.gob.mx/)
para un modelo de regresión lineal utilizando **Pytorch**

Para la el modelo de regresión fueron utilizados las siguientes bases de datos



1.   [Diferencias porcentuales en la afluencia del Transporte Público en la ZMVM](https://datos.cdmx.gob.mx/dataset/diferencias-porcentuales-en-la-afluencia-del-transporte-publico-en-la-zmvm/resource/9c8a78e5-c14e-44d0-9334-bf653928db6b) ----> **X**
2.   [Incidentes viales reportados por C5](https://datos.cdmx.gob.mx/dataset/incidentes-viales-c5/resource/c6b0fe65-137c-40d6-99c9-6c527f9b29c4) ----> **Y**

Se definieron las variables de cada base de datos y se hace una exploración de los datos para seleccionar las columnas de interés

# Preprocesamiento
"""

def get_train_data():
      #  path = '/content/drive/My Drive/HuaweiGrant/Colab-huawei/'

    path = '/data/'
    afluencia = pd.read_csv(path + 'diferencias_porcentuales_afluencia.csv')
    choque = pd.read_csv(path + 'incidentes_viales_2014_2021oct.csv', encoding='latin-1')

    # Datos de afluencia
    afluencia = afluencia[['FECHA','METRO']].astype({'FECHA': 'datetime64' , 'METRO': 'float64'}) # se modifica el tipo de dato de las columnas seleccionadas
    afluencia.update(afluencia['FECHA'].dt.strftime('%Y-%m-%d')) # y se actualiza el formato de la fecha para fines prácticos
    afluencia = afluencia.set_index('FECHA') # Se selecciona a FECHA como índice de afluencia
    afluencia = afluencia['METRO']

    # Datos de incidentes
    fechas = choque.groupby('fecha_creacion') # se agrupa la columna 'fecha de creación'
    x = fechas.count()['folio']
    ind = [i for i in x.index if '-' in i] # limieza de datos (algunas fechas tiene un mal formato, se seleccionaron las filas que tubieran la forma año-mes-dia [-])
    choque = x.loc[ind]

    # Cruce de fechas
    fecha_g = list(set(choque.index).intersection(set(afluencia.index)))
    fecha_g.sort()
    choque = choque.loc[fecha_g]  # se accede solo 'fecha_g' en incidentes
    afluencia = afluencia.loc[fecha_g] # se accede solo 'fecha_g' en afluencia

    # Test-train data
    X_train, X_test, y_train, y_test = train_test_split(afluencia, choque, train_size = 0.9)

    # Tensores
    X_train = Variable(torch.Tensor([[i] for i in X_train]))
    X_test = Variable(torch.Tensor([[i] for i in X_test]))
    y_train = Variable(torch.Tensor([[i] for i in y_train]))
    y_test = Variable(torch.Tensor([[i] for i in y_test]))

    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = get_train_data()

print(len(X_train), len(X_test), len(y_test), len(y_train))

type(X_train)

y_train

"""# Preparar data"""

#X_train, y_train = datasets.make_regression(n_samples=10, n_features=1, noise=2, random_state=1)



X_train = torch.tensor(X_train).float()
y_train = torch.tensor(y_train).float()

n_samples, n_features = X_train.shape

n_samples

"""#Modeelo"""

input_size = n_features
output_size = 1

model = nn.Linear(input_size,output_size)

"""#Optimizar"""

learning_rate = 0.0000001

criterion = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

"""# Entrenamiento"""

num_apoch = 10000
for epoch in range(num_apoch):
    y_predicted = model(X_train)
    #print(y_predicted[:5])
    #print(y_train[:5])
    loss = criterion(y_predicted, y_train)

    optimizer.zero_grad()

    loss.backward()

    optimizer.step()



    #if (epoch+1) %15 == 0:
    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')

print(model[0])

model.weight

model.weight

model.bias

model.bias

torch.save(model)

predicted = model(X_train).detach().numpy()
plt.plot(X_train,y_train, 'ro')
plt.plot(X_train, predicted, 'k')
plt.show()

predicted = model(X_train).detach().numpy()
plt.plot(X_train,y_train, 'ro')
plt.plot(X_train, predicted, 'k')
plt.show()
plt.savefig('resultados.png')

"""# Pendientes
- Investigar interacción Spark vs. Postgres (Moni)
- Definir estructura de métodos (TBD en la junta)
- Pruebas de modelos para junta de definición de métodos (Guillermo)
- Por definir: podría ser útil paralelizar Pandas https://towardsdatascience.com/make-your-own-super-pandas-using-multiproc-1c04f41944a1

# Métodos
- Preprocesamiento
- Ajustar
- Predecir
"""
